{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, linewidth=150)\n",
    "\n",
    "from copy import copy\n",
    "from itertools import combinations\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from modules.classes import Road, Vertex, Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/geodata/small_subset/roads_zh_curvy_9features.geojson\", \"r\") as roadjson:\n",
    "    original_roads = json.load(roadjson)\n",
    "\n",
    "original_road_list = [Road(road) for road in original_roads['features']]\n",
    "\n",
    "# for road in original_road_list:\n",
    "#     print(road)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import generalized scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/geodata/small_subset/roads_zh_curvy_smooth_9features.geojson\", \"r\") as roadjson:\n",
    "    smoothed_roads = json.load(roadjson)\n",
    "\n",
    "smoothed_road_list = [Road(road) for road in smoothed_roads['features']]\n",
    "\n",
    "# for road in smoothed_road_list:\n",
    "#     print(road)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Translation Vectors and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_vertices = 0\n",
    "end = 1000000\n",
    "visualize = False\n",
    "\n",
    "exagg_x_axis = 1\n",
    "\n",
    "if visualize:\n",
    "    plt.figure()\n",
    "    plt.axis('equal')\n",
    "\n",
    "d = {}\n",
    "\n",
    "# loop over roads indices\n",
    "for i in range(len(original_road_list)):\n",
    "    if i == i:\n",
    "        d[i] = {\n",
    "            'orig': {\n",
    "                'properties': original_road_list[i].properties,\n",
    "                'coordinates': []\n",
    "            },\n",
    "            'smooth': {\n",
    "                'properties': smoothed_road_list[i].properties,\n",
    "                'coordinates': []\n",
    "            },\n",
    "            'transl': {\n",
    "                'coordinates': [],\n",
    "                'vectors': []\n",
    "            }}\n",
    "        \n",
    "        if visualize:\n",
    "            original_road_list[i].exaggerate_axis(0, exagg_x_axis)\n",
    "            smoothed_road_list[i].exaggerate_axis(0, exagg_x_axis)\n",
    "            plt.plot(\n",
    "                original_road_list[i].coordinates[skip_vertices:end, 0],\n",
    "                original_road_list[i].coordinates[skip_vertices:end, 1],\n",
    "                color='blue',\n",
    "                zorder=0)\n",
    "            plt.plot(\n",
    "                smoothed_road_list[i].coordinates[skip_vertices:end, 0],\n",
    "                smoothed_road_list[i].coordinates[skip_vertices:end, 1],\n",
    "                color='red',\n",
    "                zorder=0)\n",
    "\n",
    "        # loop over road vertices' indices\n",
    "        for j in range(original_road_list[i].properties['num_vertices']):\n",
    "\n",
    "            if not (end > j >= skip_vertices):\n",
    "                continue\n",
    "\n",
    "            orig_vertex = np.array(original_road_list[i].coordinates[j])\n",
    "            smooth_vertex = np.array(smoothed_road_list[i].coordinates[j])\n",
    "            translation_vector = smooth_vertex - orig_vertex \n",
    "\n",
    "            d[i]['orig']['coordinates'].append(list(orig_vertex))\n",
    "            d[i]['smooth']['coordinates'].append(list(smooth_vertex))\n",
    "            d[i]['transl']['coordinates'].append([list(orig_vertex), [orig_vertex[0] + translation_vector[0], orig_vertex[1] + translation_vector[1]]])\n",
    "            d[i]['transl']['vectors'].append(list(translation_vector))\n",
    "\n",
    "            if visualize:\n",
    "                plt.scatter(smooth_vertex[0], smooth_vertex[1], color=(248/256, 0, 5/256), s=10)\n",
    "                plt.arrow(\n",
    "                    orig_vertex[0], orig_vertex[1],\n",
    "                    translation_vector[0], translation_vector[1],\n",
    "                    color=(168/256, 0, 200/256),\n",
    "                    head_width=6,\n",
    "                    head_length=8,\n",
    "                    length_includes_head=True)\n",
    "                plt.scatter(orig_vertex[0], orig_vertex[1], color=(69/256, 109/256, 196/256), s=10)\n",
    "            \n",
    "            \n",
    "\n",
    "if visualize:\n",
    "    plt.savefig('transl', dpi=600)                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to GEOJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transl_geojson_dict = {\n",
    "# \"type\": \"FeatureCollection\",\n",
    "# \"name\": \"roads_zh_curvy_translation_vectors\",\n",
    "# \"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:EPSG::2056\" } },\n",
    "# \"features\": []\n",
    "# }\n",
    "\n",
    "# for i in range(len(d)):\n",
    "#     transl_geojson_dict['features'].append(\n",
    "#         { \n",
    "#             \"type\": \"Feature\",\n",
    "#             \"properties\": {\"id\": i},\n",
    "#             \"geometry\": {\n",
    "#                 \"type\": \"MultiLineString\",\n",
    "#                 \"coordinates\": d[i]['transl']} }\n",
    "#     )\n",
    "\n",
    "\n",
    "# with open(\"../data/geodata/small_subset/roads_zh_curvy_translation_vectors.geojson\", \"w\") as transl_file:\n",
    "#     json.dump(transl_geojson_dict, transl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vertex_index = 0\n",
    "orig_vertices = []\n",
    "\n",
    "# iterate over roads\n",
    "for i_road in range(len(d)):\n",
    "\n",
    "    # create road-specific properties dictionary\n",
    "    props = [\n",
    "        d[i_road]['orig']['properties']['BEFAHRBARK'],\n",
    "        d[i_road]['orig']['properties']['BELAGSART'],\n",
    "        d[i_road]['orig']['properties']['OBJEKTART'],\n",
    "        d[i_road]['orig']['properties']['length'],\n",
    "        d[i_road]['orig']['properties']['num_vertices']]\n",
    "\n",
    "    # iterate over vertices\n",
    "    for i_vertex in range(d[i_road]['orig']['properties']['num_vertices']):\n",
    "\n",
    "        if i_vertex == 0:\n",
    "            connections = [global_vertex_index + 1]\n",
    "        elif i_vertex == d[i_road]['orig']['properties']['num_vertices'] - 1:\n",
    "            connections = [global_vertex_index - 1]\n",
    "        else:\n",
    "            connections = [global_vertex_index - 1, global_vertex_index + 1]\n",
    "        \n",
    "\n",
    "        orig_vertices.append(\n",
    "            Vertex(\n",
    "                index=              global_vertex_index,\n",
    "                road_index=         i_road,\n",
    "                coords=             d[i_road]['orig']['coordinates'][i_vertex],\n",
    "                translation_vector= d[i_road]['transl']['vectors'][i_vertex],\n",
    "                properties=         props,\n",
    "                connections=        connections\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        global_vertex_index += 1\n",
    "\n",
    "\n",
    "index_change_dict = {}\n",
    "num_vertices = len(orig_vertices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No spatial reduncancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in combinations(iterable=range(num_vertices), r=2):\n",
    "    if orig_vertices[i].coords == orig_vertices[j].coords:\n",
    "\n",
    "        # if orig_vertices[i].index == 271:\n",
    "        #     print(\"-----------------------------------\")\n",
    "        #     print(orig_vertices[i])\n",
    "        #     print(orig_vertices[j])\n",
    "\n",
    "        # combine all connections\n",
    "        new_connections = []\n",
    "        for connection in orig_vertices[i].connections + orig_vertices[j].connections:\n",
    "            if connection not in new_connections:\n",
    "                new_connections.append(connection)\n",
    "\n",
    "        # dictionary: old -> new\n",
    "        index_change_dict[orig_vertices[j].index] = orig_vertices[i].index\n",
    "\n",
    "        # update connections\n",
    "        orig_vertices[i].connections = copy(new_connections)\n",
    "        # overwrite second vertex\n",
    "        orig_vertices[j] = orig_vertices[i]\n",
    "\n",
    "\n",
    "# create list with unique vertices\n",
    "unique_vertices = list(dict.fromkeys(orig_vertices))\n",
    "\n",
    "# change connections according to change-dictionary\n",
    "for vertex in unique_vertices:\n",
    "    for i_connection, connection in enumerate(vertex.connections):\n",
    "        if connection in index_change_dict:\n",
    "            vertex.connections[i_connection] = index_change_dict[connection]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure continuous indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new fresh change dictionary\n",
    "index_change_dict = {}\n",
    "\n",
    "# ensure continuous indices\n",
    "for i_vertex, vertex in enumerate(unique_vertices):\n",
    "    if vertex.index != i_vertex:\n",
    "        index_change_dict[vertex.index] = i_vertex\n",
    "        vertex.index = i_vertex\n",
    "    \n",
    "    \n",
    "# change connections according to change-dictionary\n",
    "for vertex in unique_vertices:\n",
    "    for i_connection, connection in enumerate(vertex.connections):\n",
    "        if connection in index_change_dict:\n",
    "            vertex.connections[i_connection] = index_change_dict[connection]\n",
    "    \n",
    "\n",
    "    \n",
    "# index_change_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(unique_vertices)\n",
    "\n",
    "G = nx.from_numpy_matrix(g.adj_matrix)\n",
    "nx.set_node_attributes(G, g.node_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(35, 35))\n",
    "# nx.draw(G,  {n: G.nodes[n]['coords'] for n in G.nodes}, width=0.25, node_size=1, with_labels=True)\n",
    "# plt.savefig('roads_networkx', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, \"data/pickles/nx_road_graph.pickle\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f34938c28f6c73b535e93845281233bd4fde70dc64679a66d18a27957a14cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
